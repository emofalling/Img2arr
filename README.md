# `img2arr` - 干翻img2lcd

众所周知，img2lcd能够将图片转换为LCD显示的数组，但是有如下缺点：

- 操作复杂
- 最大240x240
- 古早软件
- 甚至是商业软件

所以，我决定写一个img2arr，能够将图片转换为LCD显示的数组，它将有如下特定：

- 支持多核心并行处理
- 支持CUDA/OpenCL
- 内部统一颜色管线RGBA8888，未来兼容HDR
- 图片大小无限制（就看你内存或显存多大了）
- 四阶段处理：输入 -> 预处理 -> 转换 -> 输出，大幅提高操作效率

## 安装

```bash
pip install img2arr
```

很简单。你只需要pip install img2arr，你甚至不必像img2lcd那样需要安装向导。

## 细节

### 使用什么窗口库？

**PySide6**。

至于为啥不使用其他框架，有如下原因：

- **Tk**: 性能低下，且在实时同步渲染中有潜在的性能影响（如图片随窗口缩放中，Qt就要比Tk好很多），我已经在Tk上踩过太多坑了。
- **DearPyGui**: 不支持复杂的布局器（也不指望扩展能手动计算每一个控件的位置罢），写起来麻烦
- **PyQt**: 因为不是官方出品的，在跨平台处理上有一定问题（例如，PyQt在windows上的默认显示字体是宋体，而PySide6是微软雅黑）

### 为什么不支持CUDA?

img2arr在调用核心处理库的时候，需要进行传参。  
此处传参，指的是通过void*传入一个大小不确定的数组。  
在CUDA上，这个功能被严格限制：每个CUDA核函数不能访问特定地址的显存；通过__stared分配的共享显存也不能供给用户进行写入。  
而OpenCL则没有这个限制，对这个特性十分友好

### 目录说明

### 预处理解决方案：多个预处理器的串行组合

img2arr支持多个预处理器。这大幅提高了预处理器的灵活性。

为了提高性能，可以通过标签告诉管线自己的性能优化点

- 输入复用：可以将输入缓冲区作为输出缓冲区，从而避免额外的缓冲区复制。实际使用中，在使用这类缓冲区时并不总会将输出缓冲区指定为输入缓冲区（流性质决定的）
- 只读：仅读取缓冲区，不进行修改，用于图片分析的预处理器会用到它。

为了同时兼容可能具有这些特性的多个预处理器，img2arr设计了独特的中间缓冲区策略.

首先，一个列表`mid = []`，用于存储中间缓冲区。

将生效的预处理器列表按照顺序分成三组：

- `H`: 头部预处理器。输入必须是self.img。
- `M`: 中间预处理器。输入和输出很大程度上分别不是self.img和self.pre。
- `T`: 尾部预处理器。输出必须是self.pre。

当只有一个预处理器时，这个预处理器同时具有`H`和`T`属性。  
当只有两个预处理器时，第一个预处理器具有`H`属性，第二个预处理器具有`T`属性。

默认情况下，self.pre 的数据与 self.img 相同。

从第一个预处理器开始遍历：

如果预处理器具有`H`属性，则将self.img作为输入；如果同时具有`T`属性，则将self.pre作为输出，否则添加一个中间缓冲区。

如果预处理器具有`M`属性，将上一个预处理器输出的缓冲区作为输入，然后：

- 如果这个预处理器时输入复用或只读的，则将自身的输入缓冲区作为输出。
- 否则，额外创建一个中间缓冲区作为输出。

如果预处理器具有`T`属性，将上一个预处理器输出的缓冲区作为输入：

- 如果具有只读属性，调用完之后（此时输出缓冲区一定不变），将它的输入缓冲区memcpy到self.pre。
- 否则，将self.pre作为输出。

同时，可以在预处理器列表更新时，不必重新维护一个新的mid列表。具体方案如下：

维护当前的中间项索引`i = 0`。  
当请求一个新的中间项时：

- 如果`i`小于`len(mid)`，则`arr = mid[i]`，`arr.resize`到合适的大小之后，`i += 1`。
- 否则，`mid`中添加一个符合大小的缓冲区，然后`arr = mid[i]`，`i += 1`。

在处理完最后一项之后，删除`mid`中多余的项（索引大于等于i的项）。

实际刷新时，通常采用增量更新的形式，即：一个预处理器请求刷新时，不将所有预处理器都刷新一遍，而是将该预处理器及其后继的预处理器刷新一遍。

此时可以对每个预处理器进行数组索引标记，标记所用的中间项索引。

但是部分的中间项在一次处理周期之后，会被连续的多个同时具有输入复用或只读的预处理器使用，此时，可以这样标记：  
对每个mid项，维护一个`use`列表，用于存储使用该中间项的预处理器索引，从前到后。

这样，当一个预处理器请求刷新时，索引到对应的mid时，从`use`列表的第一项开始重新刷新到其后继的所有预处理器。

这样，就实现了性能最高的前提下，灵活、简单、内存开销较小的预处理方案。
